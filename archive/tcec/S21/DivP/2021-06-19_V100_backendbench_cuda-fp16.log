./lc0 backendbench -w 6ac6ae430a1f7c2e2272a1db8e39e9d4a9113677d8a52f011ff9a15886b7c6a0 --backend-opts=cuda-fp16
[1m[31m       _
|   _ | |
|_ |_ |_|[0m v0.28.0-rc1 built Jun 19 2021
Loading weights file from: 6ac6ae430a1f7c2e2272a1db8e39e9d4a9113677d8a52f011ff9a15886b7c6a0
Creating backend [cudnn-auto]...
Switching to [cudnn-fp16]...
CUDA Runtime version: 11.1.0
Cudnn version: 8.0.5
Latest version of CUDA supported by the driver: 11.1.0
GPU: Tesla V100-SXM2-16GB
GPU memory: 15.7817 GiB
GPU clock frequency: 1530 MHz
GPU compute capability: 7.0
Benchmark batch size 1 with inference average time 3.75238ms - throughput 266.498 nps.
Benchmark batch size 2 with inference average time 4.71735ms - throughput 423.967 nps.
Benchmark batch size 3 with inference average time 4.62444ms - throughput 648.727 nps.
Benchmark batch size 4 with inference average time 5.84543ms - throughput 684.296 nps.
Benchmark batch size 5 with inference average time 3.04034ms - throughput 1644.55 nps.
Benchmark batch size 6 with inference average time 3.0851ms - throughput 1944.83 nps.
Benchmark batch size 7 with inference average time 3.0873ms - throughput 2267.35 nps.
Benchmark batch size 8 with inference average time 3.08983ms - throughput 2589.14 nps.
Benchmark batch size 9 with inference average time 3.10243ms - throughput 2900.95 nps.
Benchmark batch size 10 with inference average time 3.12582ms - throughput 3199.17 nps.
Benchmark batch size 11 with inference average time 3.14471ms - throughput 3497.94 nps.
Benchmark batch size 12 with inference average time 3.14254ms - throughput 3818.57 nps.
Benchmark batch size 13 with inference average time 3.14115ms - throughput 4138.61 nps.
Benchmark batch size 14 with inference average time 3.13017ms - throughput 4472.6 nps.
Benchmark batch size 15 with inference average time 3.1368ms - throughput 4781.94 nps.
Benchmark batch size 16 with inference average time 3.14181ms - throughput 5092.61 nps.
Benchmark batch size 17 with inference average time 3.32872ms - throughput 5107.07 nps.
Benchmark batch size 18 with inference average time 3.33875ms - throughput 5391.23 nps.
Benchmark batch size 19 with inference average time 3.34611ms - throughput 5678.24 nps.
Benchmark batch size 20 with inference average time 3.36386ms - throughput 5945.55 nps.
Benchmark batch size 21 with inference average time 3.37771ms - throughput 6217.23 nps.
Benchmark batch size 22 with inference average time 3.39323ms - throughput 6483.49 nps.
Benchmark batch size 23 with inference average time 3.40086ms - throughput 6762.99 nps.
Benchmark batch size 24 with inference average time 3.41529ms - throughput 7027.21 nps.
Benchmark batch size 25 with inference average time 3.42965ms - throughput 7289.37 nps.
Benchmark batch size 26 with inference average time 3.44576ms - throughput 7545.51 nps.
Benchmark batch size 27 with inference average time 3.47116ms - throughput 7778.38 nps.
Benchmark batch size 28 with inference average time 3.48957ms - throughput 8023.9 nps.
Benchmark batch size 29 with inference average time 3.51031ms - throughput 8261.38 nps.
Benchmark batch size 30 with inference average time 3.53305ms - throughput 8491.24 nps.
Benchmark batch size 31 with inference average time 3.56197ms - throughput 8703.04 nps.
Benchmark batch size 32 with inference average time 3.58143ms - throughput 8934.99 nps.
Benchmark batch size 33 with inference average time 4.44255ms - throughput 7428.16 nps.
Benchmark batch size 34 with inference average time 4.46617ms - throughput 7612.78 nps.
Benchmark batch size 35 with inference average time 4.5054ms - throughput 7768.46 nps.
Benchmark batch size 36 with inference average time 4.52587ms - throughput 7954.26 nps.
Benchmark batch size 37 with inference average time 4.569ms - throughput 8098.06 nps.
Benchmark batch size 38 with inference average time 4.60795ms - throughput 8246.62 nps.
Benchmark batch size 39 with inference average time 4.64501ms - throughput 8396.1 nps.
Benchmark batch size 40 with inference average time 4.68532ms - throughput 8537.3 nps.
Benchmark batch size 41 with inference average time 4.78825ms - throughput 8562.62 nps.
Benchmark batch size 42 with inference average time 4.82302ms - throughput 8708.23 nps.
Benchmark batch size 43 with inference average time 4.8712ms - throughput 8827.4 nps.
Benchmark batch size 44 with inference average time 4.92406ms - throughput 8935.71 nps.
Benchmark batch size 45 with inference average time 4.96733ms - throughput 9059.2 nps.
Benchmark batch size 46 with inference average time 5.01996ms - throughput 9163.42 nps.
Benchmark batch size 47 with inference average time 5.06199ms - throughput 9284.89 nps.
Benchmark batch size 48 with inference average time 5.08542ms - throughput 9438.74 nps.
Benchmark batch size 49 with inference average time 5.05003ms - throughput 9702.92 nps.
Benchmark batch size 50 with inference average time 5.08218ms - throughput 9838.3 nps.
Benchmark batch size 51 with inference average time 5.11798ms - throughput 9964.87 nps.
Benchmark batch size 52 with inference average time 5.13891ms - throughput 10118.9 nps.
Benchmark batch size 53 with inference average time 5.19532ms - throughput 10201.5 nps.
Benchmark batch size 54 with inference average time 5.22859ms - throughput 10327.8 nps.
Benchmark batch size 55 with inference average time 5.28313ms - throughput 10410.5 nps.
Benchmark batch size 56 with inference average time 5.3256ms - throughput 10515.3 nps.
Benchmark batch size 57 with inference average time 5.36509ms - throughput 10624.2 nps.
Benchmark batch size 58 with inference average time 5.38572ms - throughput 10769.2 nps.
Benchmark batch size 59 with inference average time 5.43623ms - throughput 10853.1 nps.
Benchmark batch size 60 with inference average time 5.47742ms - throughput 10954.1 nps.
Benchmark batch size 61 with inference average time 5.53176ms - throughput 11027.2 nps.
Benchmark batch size 62 with inference average time 5.55928ms - throughput 11152.5 nps.
Benchmark batch size 63 with inference average time 5.6198ms - throughput 11210.4 nps.
Benchmark batch size 64 with inference average time 5.65935ms - throughput 11308.7 nps.
Benchmark batch size 65 with inference average time 6.29248ms - throughput 10329.8 nps.
Benchmark batch size 66 with inference average time 6.32629ms - throughput 10432.6 nps.
Benchmark batch size 67 with inference average time 6.37626ms - throughput 10507.7 nps.
Benchmark batch size 68 with inference average time 6.41736ms - throughput 10596.3 nps.
Benchmark batch size 69 with inference average time 6.45512ms - throughput 10689.2 nps.
Benchmark batch size 70 with inference average time 6.50575ms - throughput 10759.7 nps.
Benchmark batch size 71 with inference average time 6.55206ms - throughput 10836.3 nps.
Benchmark batch size 72 with inference average time 6.59112ms - throughput 10923.8 nps.
Benchmark batch size 73 with inference average time 6.64876ms - throughput 10979.5 nps.
Benchmark batch size 74 with inference average time 6.69402ms - throughput 11054.6 nps.
Benchmark batch size 75 with inference average time 6.73462ms - throughput 11136.5 nps.
Benchmark batch size 76 with inference average time 6.7707ms - throughput 11224.8 nps.
Benchmark batch size 77 with inference average time 6.81848ms - throughput 11292.8 nps.
Benchmark batch size 78 with inference average time 6.86315ms - throughput 11365 nps.
Benchmark batch size 79 with inference average time 6.90442ms - throughput 11441.9 nps.
Benchmark batch size 80 with inference average time 6.93527ms - throughput 11535.2 nps.
Benchmark batch size 81 with inference average time 8.04412ms - throughput 10069.5 nps.
Benchmark batch size 82 with inference average time 8.1423ms - throughput 10070.9 nps.
Benchmark batch size 83 with inference average time 8.18988ms - throughput 10134.5 nps.
Benchmark batch size 84 with inference average time 8.2272ms - throughput 10210 nps.
Benchmark batch size 85 with inference average time 8.25642ms - throughput 10295 nps.
Benchmark batch size 86 with inference average time 8.27203ms - throughput 10396.5 nps.
Benchmark batch size 87 with inference average time 8.31907ms - throughput 10457.9 nps.
Benchmark batch size 88 with inference average time 8.37477ms - throughput 10507.7 nps.
Benchmark batch size 89 with inference average time 8.37715ms - throughput 10624.1 nps.
Benchmark batch size 90 with inference average time 8.41588ms - throughput 10694.1 nps.
Benchmark batch size 91 with inference average time 8.51294ms - throughput 10689.6 nps.
Benchmark batch size 92 with inference average time 8.53626ms - throughput 10777.5 nps.
Benchmark batch size 93 with inference average time 8.56161ms - throughput 10862.4 nps.
Benchmark batch size 94 with inference average time 8.57861ms - throughput 10957.5 nps.
Benchmark batch size 95 with inference average time 8.61763ms - throughput 11023.9 nps.
Benchmark batch size 96 with inference average time 8.63413ms - throughput 11118.7 nps.
Benchmark batch size 97 with inference average time 9.25759ms - throughput 10477.9 nps.
Benchmark batch size 98 with inference average time 9.22487ms - throughput 10623.5 nps.
Benchmark batch size 99 with inference average time 9.3194ms - throughput 10623 nps.
Benchmark batch size 100 with inference average time 9.32927ms - throughput 10719 nps.
Benchmark batch size 101 with inference average time 9.37441ms - throughput 10774 nps.
Benchmark batch size 102 with inference average time 9.44034ms - throughput 10804.7 nps.
Benchmark batch size 103 with inference average time 9.41733ms - throughput 10937.3 nps.
Benchmark batch size 104 with inference average time 9.47498ms - throughput 10976.3 nps.
Benchmark batch size 105 with inference average time 9.48708ms - throughput 11067.7 nps.
Benchmark batch size 106 with inference average time 9.49283ms - throughput 11166.3 nps.
Benchmark batch size 107 with inference average time 9.52087ms - throughput 11238.5 nps.
Benchmark batch size 108 with inference average time 9.5044ms - throughput 11363.2 nps.
Benchmark batch size 109 with inference average time 9.5505ms - throughput 11413 nps.
Benchmark batch size 110 with inference average time 9.57261ms - throughput 11491.1 nps.
Benchmark batch size 111 with inference average time 9.6112ms - throughput 11549 nps.
Benchmark batch size 112 with inference average time 9.6397ms - throughput 11618.6 nps.
Benchmark batch size 113 with inference average time 9.48306ms - throughput 11916 nps.
Benchmark batch size 114 with inference average time 9.50011ms - throughput 11999.9 nps.
Benchmark batch size 115 with inference average time 9.57937ms - throughput 12005 nps.
Benchmark batch size 116 with inference average time 9.60133ms - throughput 12081.7 nps.
Benchmark batch size 117 with inference average time 9.62395ms - throughput 12157.2 nps.
Benchmark batch size 118 with inference average time 9.67564ms - throughput 12195.6 nps.
Benchmark batch size 119 with inference average time 9.69897ms - throughput 12269.3 nps.
Benchmark batch size 120 with inference average time 9.74248ms - throughput 12317.2 nps.
Benchmark batch size 121 with inference average time 9.77865ms - throughput 12373.9 nps.
Benchmark batch size 122 with inference average time 9.80525ms - throughput 12442.3 nps.
Benchmark batch size 123 with inference average time 9.88064ms - throughput 12448.6 nps.
Benchmark batch size 124 with inference average time 9.89735ms - throughput 12528.6 nps.
Benchmark batch size 125 with inference average time 9.93301ms - throughput 12584.3 nps.
Benchmark batch size 126 with inference average time 10.0032ms - throughput 12595.9 nps.
Benchmark batch size 127 with inference average time 10.074ms - throughput 12606.7 nps.
Benchmark batch size 128 with inference average time 10.0839ms - throughput 12693.6 nps.
Benchmark batch size 129 with inference average time 10.8651ms - throughput 11872.8 nps.
Benchmark batch size 130 with inference average time 10.9238ms - throughput 11900.6 nps.
Benchmark batch size 131 with inference average time 10.9508ms - throughput 11962.6 nps.
Benchmark batch size 132 with inference average time 10.9999ms - throughput 12000.1 nps.
Benchmark batch size 133 with inference average time 11.0375ms - throughput 12049.9 nps.
Benchmark batch size 134 with inference average time 11.0947ms - throughput 12077.8 nps.
Benchmark batch size 135 with inference average time 11.1265ms - throughput 12133.2 nps.
Benchmark batch size 136 with inference average time 11.1839ms - throughput 12160.3 nps.
Benchmark batch size 137 with inference average time 11.1571ms - throughput 12279.1 nps.
Benchmark batch size 138 with inference average time 11.1991ms - throughput 12322.4 nps.
Benchmark batch size 139 with inference average time 11.2929ms - throughput 12308.6 nps.
Benchmark batch size 140 with inference average time 11.3284ms - throughput 12358.3 nps.
Benchmark batch size 141 with inference average time 11.3521ms - throughput 12420.6 nps.
Benchmark batch size 142 with inference average time 11.3867ms - throughput 12470.7 nps.
Benchmark batch size 143 with inference average time 11.4583ms - throughput 12480 nps.
Benchmark batch size 144 with inference average time 11.5091ms - throughput 12511.8 nps.
Benchmark batch size 145 with inference average time 11.5495ms - throughput 12554.7 nps.
Benchmark batch size 146 with inference average time 11.6321ms - throughput 12551.4 nps.
Benchmark batch size 147 with inference average time 11.6827ms - throughput 12582.7 nps.
Benchmark batch size 148 with inference average time 11.724ms - throughput 12623.7 nps.
Benchmark batch size 149 with inference average time 11.8027ms - throughput 12624.2 nps.
Benchmark batch size 150 with inference average time 11.8228ms - throughput 12687.3 nps.
Benchmark batch size 151 with inference average time 11.8346ms - throughput 12759.2 nps.
Benchmark batch size 152 with inference average time 11.921ms - throughput 12750.6 nps.
Benchmark batch size 153 with inference average time 12.0261ms - throughput 12722.3 nps.
Benchmark batch size 154 with inference average time 12.0694ms - throughput 12759.5 nps.
Benchmark batch size 155 with inference average time 12.0462ms - throughput 12867.2 nps.
Benchmark batch size 156 with inference average time 12.0756ms - throughput 12918.6 nps.
Benchmark batch size 157 with inference average time 12.1696ms - throughput 12901 nps.
Benchmark batch size 158 with inference average time 12.2655ms - throughput 12881.6 nps.
Benchmark batch size 159 with inference average time 12.3348ms - throughput 12890.3 nps.
Benchmark batch size 160 with inference average time 12.3147ms - throughput 12992.6 nps.
Benchmark batch size 161 with inference average time 13.1ms - throughput 12290.1 nps.
Benchmark batch size 162 with inference average time 13.1738ms - throughput 12297.1 nps.
Benchmark batch size 163 with inference average time 13.3062ms - throughput 12250 nps.
Benchmark batch size 164 with inference average time 13.3676ms - throughput 12268.5 nps.
Benchmark batch size 165 with inference average time 13.4065ms - throughput 12307.4 nps.
Benchmark batch size 166 with inference average time 13.565ms - throughput 12237.4 nps.
Benchmark batch size 167 with inference average time 13.517ms - throughput 12354.8 nps.
Benchmark batch size 168 with inference average time 13.3451ms - throughput 12588.9 nps.
Benchmark batch size 169 with inference average time 13.6154ms - throughput 12412.4 nps.
Benchmark batch size 170 with inference average time 13.6946ms - throughput 12413.7 nps.
Benchmark batch size 171 with inference average time 13.6714ms - throughput 12507.8 nps.
Benchmark batch size 172 with inference average time 13.9119ms - throughput 12363.5 nps.
Benchmark batch size 173 with inference average time 13.8936ms - throughput 12451.8 nps.
Benchmark batch size 174 with inference average time 13.7917ms - throughput 12616.3 nps.
Benchmark batch size 175 with inference average time 14.0537ms - throughput 12452.3 nps.
Benchmark batch size 176 with inference average time 14.0097ms - throughput 12562.7 nps.
Benchmark batch size 177 with inference average time 14.2572ms - throughput 12414.8 nps.
Benchmark batch size 178 with inference average time 14.25ms - throughput 12491.3 nps.
Benchmark batch size 179 with inference average time 14.1886ms - throughput 12615.7 nps.
Benchmark batch size 180 with inference average time 14.2646ms - throughput 12618.6 nps.
Benchmark batch size 181 with inference average time 14.2876ms - throughput 12668.3 nps.
Benchmark batch size 182 with inference average time 14.301ms - throughput 12726.4 nps.
Benchmark batch size 183 with inference average time 14.3111ms - throughput 12787.2 nps.
Benchmark batch size 184 with inference average time 14.4101ms - throughput 12768.8 nps.
Benchmark batch size 185 with inference average time 14.4281ms - throughput 12822.2 nps.
Benchmark batch size 186 with inference average time 14.5422ms - throughput 12790.4 nps.
Benchmark batch size 187 with inference average time 14.5391ms - throughput 12861.9 nps.
Benchmark batch size 188 with inference average time 14.5628ms - throughput 12909.6 nps.
Benchmark batch size 189 with inference average time 14.6218ms - throughput 12925.9 nps.
Benchmark batch size 190 with inference average time 14.6672ms - throughput 12954.1 nps.
Benchmark batch size 191 with inference average time 14.7301ms - throughput 12966.6 nps.
Benchmark batch size 192 with inference average time 14.8281ms - throughput 12948.4 nps.
Benchmark batch size 193 with inference average time 15.0698ms - throughput 12807.1 nps.
Benchmark batch size 194 with inference average time 15.0799ms - throughput 12864.8 nps.
Benchmark batch size 195 with inference average time 15.037ms - throughput 12968 nps.
Benchmark batch size 196 with inference average time 15.1294ms - throughput 12954.9 nps.
Benchmark batch size 197 with inference average time 15.205ms - throughput 12956.3 nps.
Benchmark batch size 198 with inference average time 15.1621ms - throughput 13058.9 nps.
Benchmark batch size 199 with inference average time 15.178ms - throughput 13111.1 nps.
Benchmark batch size 200 with inference average time 15.1365ms - throughput 13213.1 nps.
Benchmark batch size 201 with inference average time 15.1989ms - throughput 13224.6 nps.
Benchmark batch size 202 with inference average time 15.2224ms - throughput 13269.9 nps.
Benchmark batch size 203 with inference average time 15.2594ms - throughput 13303.3 nps.
Benchmark batch size 204 with inference average time 15.377ms - throughput 13266.6 nps.
Benchmark batch size 205 with inference average time 15.4042ms - throughput 13308 nps.
Benchmark batch size 206 with inference average time 15.4648ms - throughput 13320.6 nps.
Benchmark batch size 207 with inference average time 15.4775ms - throughput 13374.3 nps.
Benchmark batch size 208 with inference average time 15.5164ms - throughput 13405.1 nps.
Benchmark batch size 209 with inference average time 15.4992ms - throughput 13484.5 nps.
Benchmark batch size 210 with inference average time 15.495ms - throughput 13552.7 nps.
Benchmark batch size 211 with inference average time 15.5584ms - throughput 13561.8 nps.
Benchmark batch size 212 with inference average time 15.6477ms - throughput 13548.3 nps.
Benchmark batch size 213 with inference average time 15.5908ms - throughput 13661.9 nps.
Benchmark batch size 214 with inference average time 15.7416ms - throughput 13594.6 nps.
Benchmark batch size 215 with inference average time 15.7812ms - throughput 13623.8 nps.
Benchmark batch size 216 with inference average time 15.7631ms - throughput 13702.9 nps.
Benchmark batch size 217 with inference average time 15.7506ms - throughput 13777.3 nps.
Benchmark batch size 218 with inference average time 15.836ms - throughput 13766.1 nps.
Benchmark batch size 219 with inference average time 15.9397ms - throughput 13739.3 nps.
Benchmark batch size 220 with inference average time 16.023ms - throughput 13730.3 nps.
Benchmark batch size 221 with inference average time 15.9696ms - throughput 13838.8 nps.
Benchmark batch size 222 with inference average time 15.9734ms - throughput 13898.1 nps.
Benchmark batch size 223 with inference average time 15.9833ms - throughput 13952.1 nps.
Benchmark batch size 224 with inference average time 16.0456ms - throughput 13960.2 nps.
Benchmark batch size 225 with inference average time 16.6707ms - throughput 13496.8 nps.
Benchmark batch size 226 with inference average time 16.7704ms - throughput 13476.1 nps.
Benchmark batch size 227 with inference average time 16.7762ms - throughput 13531.1 nps.
Benchmark batch size 228 with inference average time 16.7588ms - throughput 13604.8 nps.
Benchmark batch size 229 with inference average time 16.896ms - throughput 13553.5 nps.
Benchmark batch size 230 with inference average time 16.9214ms - throughput 13592.3 nps.
Benchmark batch size 231 with inference average time 16.9276ms - throughput 13646.3 nps.
Benchmark batch size 232 with inference average time 17.0563ms - throughput 13602 nps.
Benchmark batch size 233 with inference average time 17.074ms - throughput 13646.4 nps.
Benchmark batch size 234 with inference average time 17.0831ms - throughput 13697.7 nps.
Benchmark batch size 235 with inference average time 17.1302ms - throughput 13718.5 nps.
Benchmark batch size 236 with inference average time 17.2288ms - throughput 13698 nps.
Benchmark batch size 237 with inference average time 17.3269ms - throughput 13678.1 nps.
Benchmark batch size 238 with inference average time 17.3821ms - throughput 13692.2 nps.
Benchmark batch size 239 with inference average time 17.452ms - throughput 13694.7 nps.
Benchmark batch size 240 with inference average time 17.5333ms - throughput 13688.3 nps.
Benchmark batch size 241 with inference average time 17.6914ms - throughput 13622.5 nps.
Benchmark batch size 242 with inference average time 17.6243ms - throughput 13731.1 nps.
Benchmark batch size 243 with inference average time 17.6883ms - throughput 13737.9 nps.
Benchmark batch size 244 with inference average time 17.7982ms - throughput 13709.3 nps.
Benchmark batch size 245 with inference average time 17.9797ms - throughput 13626.5 nps.
Benchmark batch size 246 with inference average time 18.0866ms - throughput 13601.3 nps.
Benchmark batch size 247 with inference average time 18.0516ms - throughput 13683 nps.
Benchmark batch size 248 with inference average time 18.0576ms - throughput 13733.8 nps.
Benchmark batch size 249 with inference average time 18.2808ms - throughput 13620.8 nps.
Benchmark batch size 250 with inference average time 18.2673ms - throughput 13685.7 nps.
Benchmark batch size 251 with inference average time 18.257ms - throughput 13748.1 nps.
Benchmark batch size 252 with inference average time 18.4548ms - throughput 13655 nps.
Benchmark batch size 253 with inference average time 18.5902ms - throughput 13609.4 nps.
Benchmark batch size 254 with inference average time 18.7278ms - throughput 13562.7 nps.
Benchmark batch size 255 with inference average time 18.747ms - throughput 13602.2 nps.
Benchmark batch size 256 with inference average time 18.6929ms - throughput 13695 nps.
