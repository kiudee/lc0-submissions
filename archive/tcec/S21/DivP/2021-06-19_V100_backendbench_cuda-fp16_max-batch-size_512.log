./lc0 backendbench -w 6ac6ae430a1f7c2e2272a1db8e39e9d4a9113677d8a52f011ff9a15886b7c6a0 --backend-opts=cuda-fp16 --max-batch-size=512

[1m[31m       _
|   _ | |
|_ |_ |_|[0m v0.28.0-rc1 built Jun 19 2021
Loading weights file from: 6ac6ae430a1f7c2e2272a1db8e39e9d4a9113677d8a52f011ff9a15886b7c6a0
Creating backend [cudnn-auto]...
Switching to [cudnn-fp16]...
CUDA Runtime version: 11.1.0
Cudnn version: 8.0.5
Latest version of CUDA supported by the driver: 11.1.0
GPU: Tesla V100-SXM2-16GB
GPU memory: 15.7817 GiB
GPU clock frequency: 1530 MHz
GPU compute capability: 7.0
Benchmark batch size 1 with inference average time 3.73616ms - throughput 267.654 nps.
Benchmark batch size 2 with inference average time 4.75535ms - throughput 420.579 nps.
Benchmark batch size 3 with inference average time 4.61436ms - throughput 650.144 nps.
Benchmark batch size 4 with inference average time 5.87965ms - throughput 680.312 nps.
Benchmark batch size 5 with inference average time 3.09681ms - throughput 1614.56 nps.
Benchmark batch size 6 with inference average time 3.12704ms - throughput 1918.75 nps.
Benchmark batch size 7 with inference average time 3.13876ms - throughput 2230.18 nps.
Benchmark batch size 8 with inference average time 3.14435ms - throughput 2544.25 nps.
Benchmark batch size 9 with inference average time 3.15729ms - throughput 2850.54 nps.
Benchmark batch size 10 with inference average time 3.17254ms - throughput 3152.05 nps.
Benchmark batch size 11 with inference average time 3.19083ms - throughput 3447.38 nps.
Benchmark batch size 12 with inference average time 3.18358ms - throughput 3769.35 nps.
Benchmark batch size 13 with inference average time 3.18313ms - throughput 4084.02 nps.
Benchmark batch size 14 with inference average time 3.17299ms - throughput 4412.24 nps.
Benchmark batch size 15 with inference average time 3.17727ms - throughput 4721.03 nps.
Benchmark batch size 16 with inference average time 3.18619ms - throughput 5021.67 nps.
Benchmark batch size 17 with inference average time 3.32906ms - throughput 5106.54 nps.
Benchmark batch size 18 with inference average time 3.3344ms - throughput 5398.26 nps.
Benchmark batch size 19 with inference average time 3.34025ms - throughput 5688.19 nps.
Benchmark batch size 20 with inference average time 3.3577ms - throughput 5956.45 nps.
Benchmark batch size 21 with inference average time 3.37577ms - throughput 6220.81 nps.
Benchmark batch size 22 with inference average time 3.38558ms - throughput 6498.14 nps.
Benchmark batch size 23 with inference average time 3.39222ms - throughput 6780.21 nps.
Benchmark batch size 24 with inference average time 3.40683ms - throughput 7044.67 nps.
Benchmark batch size 25 with inference average time 3.41383ms - throughput 7323.16 nps.
Benchmark batch size 26 with inference average time 3.42993ms - throughput 7580.33 nps.
Benchmark batch size 27 with inference average time 3.44956ms - throughput 7827.08 nps.
Benchmark batch size 28 with inference average time 3.46832ms - throughput 8073.06 nps.
Benchmark batch size 29 with inference average time 3.4937ms - throughput 8300.65 nps.
Benchmark batch size 30 with inference average time 3.51568ms - throughput 8533.2 nps.
Benchmark batch size 31 with inference average time 3.54633ms - throughput 8741.43 nps.
Benchmark batch size 32 with inference average time 3.57117ms - throughput 8960.65 nps.
Benchmark batch size 33 with inference average time 4.43822ms - throughput 7435.41 nps.
Benchmark batch size 34 with inference average time 4.48182ms - throughput 7586.21 nps.
Benchmark batch size 35 with inference average time 4.53317ms - throughput 7720.87 nps.
Benchmark batch size 36 with inference average time 4.55064ms - throughput 7910.97 nps.
Benchmark batch size 37 with inference average time 4.59629ms - throughput 8049.97 nps.
Benchmark batch size 38 with inference average time 4.62215ms - throughput 8221.27 nps.
Benchmark batch size 39 with inference average time 4.67544ms - throughput 8341.46 nps.
Benchmark batch size 40 with inference average time 4.71733ms - throughput 8479.38 nps.
Benchmark batch size 41 with inference average time 4.8166ms - throughput 8512.24 nps.
Benchmark batch size 42 with inference average time 4.8486ms - throughput 8662.3 nps.
Benchmark batch size 43 with inference average time 4.90963ms - throughput 8758.29 nps.
Benchmark batch size 44 with inference average time 4.93314ms - throughput 8919.26 nps.
Benchmark batch size 45 with inference average time 4.9928ms - throughput 9012.99 nps.
Benchmark batch size 46 with inference average time 5.03306ms - throughput 9139.58 nps.
Benchmark batch size 47 with inference average time 5.08017ms - throughput 9251.66 nps.
Benchmark batch size 48 with inference average time 5.10353ms - throughput 9405.26 nps.
Benchmark batch size 49 with inference average time 5.04365ms - throughput 9715.18 nps.
Benchmark batch size 50 with inference average time 5.07732ms - throughput 9847.72 nps.
Benchmark batch size 51 with inference average time 5.1165ms - throughput 9967.76 nps.
Benchmark batch size 52 with inference average time 5.14177ms - throughput 10113.2 nps.
Benchmark batch size 53 with inference average time 5.19493ms - throughput 10202.3 nps.
Benchmark batch size 54 with inference average time 5.2216ms - throughput 10341.6 nps.
Benchmark batch size 55 with inference average time 5.27898ms - throughput 10418.7 nps.
Benchmark batch size 56 with inference average time 5.32025ms - throughput 10525.8 nps.
Benchmark batch size 57 with inference average time 5.35836ms - throughput 10637.6 nps.
Benchmark batch size 58 with inference average time 5.3767ms - throughput 10787.3 nps.
Benchmark batch size 59 with inference average time 5.4358ms - throughput 10854 nps.
Benchmark batch size 60 with inference average time 5.46293ms - throughput 10983.1 nps.
Benchmark batch size 61 with inference average time 5.52057ms - throughput 11049.6 nps.
Benchmark batch size 62 with inference average time 5.55293ms - throughput 11165.3 nps.
Benchmark batch size 63 with inference average time 5.61286ms - throughput 11224.2 nps.
Benchmark batch size 64 with inference average time 5.65157ms - throughput 11324.3 nps.
Benchmark batch size 65 with inference average time 6.28761ms - throughput 10337.8 nps.
Benchmark batch size 66 with inference average time 6.32388ms - throughput 10436.6 nps.
Benchmark batch size 67 with inference average time 6.36932ms - throughput 10519.2 nps.
Benchmark batch size 68 with inference average time 6.40688ms - throughput 10613.6 nps.
Benchmark batch size 69 with inference average time 6.45098ms - throughput 10696.1 nps.
Benchmark batch size 70 with inference average time 6.50557ms - throughput 10760 nps.
Benchmark batch size 71 with inference average time 6.54627ms - throughput 10845.9 nps.
Benchmark batch size 72 with inference average time 6.59139ms - throughput 10923.3 nps.
Benchmark batch size 73 with inference average time 6.65164ms - throughput 10974.7 nps.
Benchmark batch size 74 with inference average time 6.69707ms - throughput 11049.6 nps.
Benchmark batch size 75 with inference average time 6.73248ms - throughput 11140 nps.
Benchmark batch size 76 with inference average time 6.76733ms - throughput 11230.4 nps.
Benchmark batch size 77 with inference average time 6.8147ms - throughput 11299.1 nps.
Benchmark batch size 78 with inference average time 6.8588ms - throughput 11372.2 nps.
Benchmark batch size 79 with inference average time 6.89877ms - throughput 11451.3 nps.
Benchmark batch size 80 with inference average time 6.937ms - throughput 11532.4 nps.
Benchmark batch size 81 with inference average time 8.03342ms - throughput 10082.9 nps.
Benchmark batch size 82 with inference average time 8.13368ms - throughput 10081.5 nps.
Benchmark batch size 83 with inference average time 8.18281ms - throughput 10143.2 nps.
Benchmark batch size 84 with inference average time 8.21154ms - throughput 10229.5 nps.
Benchmark batch size 85 with inference average time 8.25469ms - throughput 10297.2 nps.
Benchmark batch size 86 with inference average time 8.27641ms - throughput 10391 nps.
Benchmark batch size 87 with inference average time 8.32189ms - throughput 10454.4 nps.
Benchmark batch size 88 with inference average time 8.36861ms - throughput 10515.5 nps.
Benchmark batch size 89 with inference average time 8.37484ms - throughput 10627.1 nps.
Benchmark batch size 90 with inference average time 8.41551ms - throughput 10694.5 nps.
Benchmark batch size 91 with inference average time 8.51415ms - throughput 10688.1 nps.
Benchmark batch size 92 with inference average time 8.53893ms - throughput 10774.2 nps.
Benchmark batch size 93 with inference average time 8.57141ms - throughput 10850 nps.
Benchmark batch size 94 with inference average time 8.57733ms - throughput 10959.1 nps.
Benchmark batch size 95 with inference average time 8.61092ms - throughput 11032.5 nps.
Benchmark batch size 96 with inference average time 8.62659ms - throughput 11128.4 nps.
Benchmark batch size 97 with inference average time 9.23798ms - throughput 10500.1 nps.
Benchmark batch size 98 with inference average time 9.21292ms - throughput 10637.2 nps.
Benchmark batch size 99 with inference average time 9.31861ms - throughput 10623.9 nps.
Benchmark batch size 100 with inference average time 9.33731ms - throughput 10709.7 nps.
Benchmark batch size 101 with inference average time 9.37995ms - throughput 10767.7 nps.
Benchmark batch size 102 with inference average time 9.44611ms - throughput 10798.1 nps.
Benchmark batch size 103 with inference average time 9.41807ms - throughput 10936.4 nps.
Benchmark batch size 104 with inference average time 9.48997ms - throughput 10958.9 nps.
Benchmark batch size 105 with inference average time 9.49409ms - throughput 11059.5 nps.
Benchmark batch size 106 with inference average time 9.50314ms - throughput 11154.2 nps.
Benchmark batch size 107 with inference average time 9.52426ms - throughput 11234.5 nps.
Benchmark batch size 108 with inference average time 9.50082ms - throughput 11367.4 nps.
Benchmark batch size 109 with inference average time 9.5677ms - throughput 11392.5 nps.
Benchmark batch size 110 with inference average time 9.58197ms - throughput 11479.9 nps.
Benchmark batch size 111 with inference average time 9.61402ms - throughput 11545.6 nps.
Benchmark batch size 112 with inference average time 9.64756ms - throughput 11609.2 nps.
Benchmark batch size 113 with inference average time 9.45135ms - throughput 11956 nps.
Benchmark batch size 114 with inference average time 9.4828ms - throughput 12021.8 nps.
Benchmark batch size 115 with inference average time 9.52675ms - throughput 12071.3 nps.
Benchmark batch size 116 with inference average time 9.55921ms - throughput 12134.9 nps.
Benchmark batch size 117 with inference average time 9.58167ms - throughput 12210.8 nps.
Benchmark batch size 118 with inference average time 9.61439ms - throughput 12273.3 nps.
Benchmark batch size 119 with inference average time 9.66157ms - throughput 12316.8 nps.
Benchmark batch size 120 with inference average time 9.7152ms - throughput 12351.8 nps.
Benchmark batch size 121 with inference average time 9.74471ms - throughput 12417 nps.
Benchmark batch size 122 with inference average time 9.75889ms - throughput 12501.4 nps.
Benchmark batch size 123 with inference average time 9.81217ms - throughput 12535.4 nps.
Benchmark batch size 124 with inference average time 9.85525ms - throughput 12582.1 nps.
Benchmark batch size 125 with inference average time 9.8969ms - throughput 12630.2 nps.
Benchmark batch size 126 with inference average time 9.96864ms - throughput 12639.6 nps.
Benchmark batch size 127 with inference average time 10.0061ms - throughput 12692.3 nps.
Benchmark batch size 128 with inference average time 10.0488ms - throughput 12737.8 nps.
Benchmark batch size 129 with inference average time 10.8458ms - throughput 11894 nps.
Benchmark batch size 130 with inference average time 10.895ms - throughput 11932 nps.
Benchmark batch size 131 with inference average time 10.9104ms - throughput 12006.9 nps.
Benchmark batch size 132 with inference average time 10.9696ms - throughput 12033.3 nps.
Benchmark batch size 133 with inference average time 11.0154ms - throughput 12074 nps.
Benchmark batch size 134 with inference average time 11.0497ms - throughput 12127.1 nps.
Benchmark batch size 135 with inference average time 11.0735ms - throughput 12191.2 nps.
Benchmark batch size 136 with inference average time 11.1436ms - throughput 12204.3 nps.
Benchmark batch size 137 with inference average time 11.1525ms - throughput 12284.3 nps.
Benchmark batch size 138 with inference average time 11.1849ms - throughput 12338.1 nps.
Benchmark batch size 139 with inference average time 11.2312ms - throughput 12376.2 nps.
Benchmark batch size 140 with inference average time 11.2879ms - throughput 12402.7 nps.
Benchmark batch size 141 with inference average time 11.3093ms - throughput 12467.6 nps.
Benchmark batch size 142 with inference average time 11.3993ms - throughput 12456.9 nps.
Benchmark batch size 143 with inference average time 11.4278ms - throughput 12513.4 nps.
Benchmark batch size 144 with inference average time 11.4569ms - throughput 12568.8 nps.
Benchmark batch size 145 with inference average time 11.536ms - throughput 12569.3 nps.
Benchmark batch size 146 with inference average time 11.5898ms - throughput 12597.3 nps.
Benchmark batch size 147 with inference average time 11.6937ms - throughput 12570.8 nps.
Benchmark batch size 148 with inference average time 11.722ms - throughput 12625.9 nps.
Benchmark batch size 149 with inference average time 11.7378ms - throughput 12694 nps.
Benchmark batch size 150 with inference average time 11.7871ms - throughput 12725.8 nps.
Benchmark batch size 151 with inference average time 11.828ms - throughput 12766.3 nps.
Benchmark batch size 152 with inference average time 11.883ms - throughput 12791.4 nps.
Benchmark batch size 153 with inference average time 11.98ms - throughput 12771.2 nps.
Benchmark batch size 154 with inference average time 12.0112ms - throughput 12821.4 nps.
Benchmark batch size 155 with inference average time 12.0102ms - throughput 12905.7 nps.
Benchmark batch size 156 with inference average time 12.0635ms - throughput 12931.6 nps.
Benchmark batch size 157 with inference average time 12.1207ms - throughput 12953 nps.
Benchmark batch size 158 with inference average time 12.186ms - throughput 12965.7 nps.
Benchmark batch size 159 with inference average time 12.2579ms - throughput 12971.2 nps.
Benchmark batch size 160 with inference average time 12.2387ms - throughput 13073.3 nps.
Benchmark batch size 161 with inference average time 13.0452ms - throughput 12341.7 nps.
Benchmark batch size 162 with inference average time 13.1238ms - throughput 12344 nps.
Benchmark batch size 163 with inference average time 13.2134ms - throughput 12336 nps.
Benchmark batch size 164 with inference average time 13.2107ms - throughput 12414.2 nps.
Benchmark batch size 165 with inference average time 13.374ms - throughput 12337.4 nps.
Benchmark batch size 166 with inference average time 13.5391ms - throughput 12260.8 nps.
Benchmark batch size 167 with inference average time 13.5644ms - throughput 12311.7 nps.
Benchmark batch size 168 with inference average time 13.4118ms - throughput 12526.3 nps.
Benchmark batch size 169 with inference average time 13.623ms - throughput 12405.5 nps.
Benchmark batch size 170 with inference average time 13.6354ms - throughput 12467.5 nps.
Benchmark batch size 171 with inference average time 13.6289ms - throughput 12546.8 nps.
Benchmark batch size 172 with inference average time 13.7783ms - throughput 12483.4 nps.
Benchmark batch size 173 with inference average time 13.7982ms - throughput 12537.9 nps.
Benchmark batch size 174 with inference average time 13.7732ms - throughput 12633.2 nps.
Benchmark batch size 175 with inference average time 14.0085ms - throughput 12492.4 nps.
Benchmark batch size 176 with inference average time 14.0793ms - throughput 12500.6 nps.
Benchmark batch size 177 with inference average time 14.2417ms - throughput 12428.3 nps.
Benchmark batch size 178 with inference average time 14.2116ms - throughput 12525 nps.
Benchmark batch size 179 with inference average time 14.1385ms - throughput 12660.4 nps.
Benchmark batch size 180 with inference average time 14.1743ms - throughput 12699 nps.
Benchmark batch size 181 with inference average time 14.2323ms - throughput 12717.5 nps.
Benchmark batch size 182 with inference average time 14.3143ms - throughput 12714.5 nps.
Benchmark batch size 183 with inference average time 14.2865ms - throughput 12809.3 nps.
Benchmark batch size 184 with inference average time 14.4217ms - throughput 12758.5 nps.
Benchmark batch size 185 with inference average time 14.3865ms - throughput 12859.3 nps.
Benchmark batch size 186 with inference average time 14.4468ms - throughput 12874.8 nps.
Benchmark batch size 187 with inference average time 14.4843ms - throughput 12910.6 nps.
Benchmark batch size 188 with inference average time 14.5476ms - throughput 12923.1 nps.
Benchmark batch size 189 with inference average time 14.5655ms - throughput 12975.8 nps.
Benchmark batch size 190 with inference average time 14.5976ms - throughput 13015.9 nps.
Benchmark batch size 191 with inference average time 14.6011ms - throughput 13081.2 nps.
Benchmark batch size 192 with inference average time 14.7222ms - throughput 13041.5 nps.
Benchmark batch size 193 with inference average time 15.0376ms - throughput 12834.5 nps.
Benchmark batch size 194 with inference average time 15.0391ms - throughput 12899.7 nps.
Benchmark batch size 195 with inference average time 15.021ms - throughput 12981.8 nps.
Benchmark batch size 196 with inference average time 15.0504ms - throughput 13022.9 nps.
Benchmark batch size 197 with inference average time 15.0801ms - throughput 13063.6 nps.
Benchmark batch size 198 with inference average time 15.0827ms - throughput 13127.6 nps.
Benchmark batch size 199 with inference average time 15.1426ms - throughput 13141.8 nps.
Benchmark batch size 200 with inference average time 15.1059ms - throughput 13239.8 nps.
Benchmark batch size 201 with inference average time 15.172ms - throughput 13248.1 nps.
Benchmark batch size 202 with inference average time 15.1924ms - throughput 13296.1 nps.
Benchmark batch size 203 with inference average time 15.2464ms - throughput 13314.7 nps.
Benchmark batch size 204 with inference average time 15.2882ms - throughput 13343.6 nps.
Benchmark batch size 205 with inference average time 15.3137ms - throughput 13386.7 nps.
Benchmark batch size 206 with inference average time 15.3832ms - throughput 13391.2 nps.
Benchmark batch size 207 with inference average time 15.4117ms - throughput 13431.3 nps.
Benchmark batch size 208 with inference average time 15.4592ms - throughput 13454.7 nps.
Benchmark batch size 209 with inference average time 15.4617ms - throughput 13517.3 nps.
Benchmark batch size 210 with inference average time 15.4662ms - throughput 13578 nps.
Benchmark batch size 211 with inference average time 15.5132ms - throughput 13601.4 nps.
Benchmark batch size 212 with inference average time 15.5605ms - throughput 13624.2 nps.
Benchmark batch size 213 with inference average time 15.5607ms - throughput 13688.3 nps.
Benchmark batch size 214 with inference average time 15.6807ms - throughput 13647.3 nps.
Benchmark batch size 215 with inference average time 15.7258ms - throughput 13671.8 nps.
Benchmark batch size 216 with inference average time 15.7283ms - throughput 13733.2 nps.
Benchmark batch size 217 with inference average time 15.7123ms - throughput 13810.9 nps.
Benchmark batch size 218 with inference average time 15.78ms - throughput 13814.9 nps.
Benchmark batch size 219 with inference average time 15.8704ms - throughput 13799.3 nps.
Benchmark batch size 220 with inference average time 15.9361ms - throughput 13805.1 nps.
Benchmark batch size 221 with inference average time 15.9502ms - throughput 13855.6 nps.
Benchmark batch size 222 with inference average time 15.9181ms - throughput 13946.4 nps.
Benchmark batch size 223 with inference average time 15.9478ms - throughput 13983.2 nps.
Benchmark batch size 224 with inference average time 15.9924ms - throughput 14006.7 nps.
Benchmark batch size 225 with inference average time 16.6575ms - throughput 13507.4 nps.
Benchmark batch size 226 with inference average time 16.7397ms - throughput 13500.9 nps.
Benchmark batch size 227 with inference average time 16.7568ms - throughput 13546.8 nps.
Benchmark batch size 228 with inference average time 16.7175ms - throughput 13638.4 nps.
Benchmark batch size 229 with inference average time 16.8324ms - throughput 13604.8 nps.
Benchmark batch size 230 with inference average time 16.8771ms - throughput 13628 nps.
Benchmark batch size 231 with inference average time 16.8925ms - throughput 13674.7 nps.
Benchmark batch size 232 with inference average time 17.0176ms - throughput 13632.9 nps.
Benchmark batch size 233 with inference average time 17.0357ms - throughput 13677.2 nps.
Benchmark batch size 234 with inference average time 17.064ms - throughput 13713.1 nps.
Benchmark batch size 235 with inference average time 17.1302ms - throughput 13718.5 nps.
Benchmark batch size 236 with inference average time 17.1982ms - throughput 13722.4 nps.
Benchmark batch size 237 with inference average time 17.2634ms - throughput 13728.5 nps.
Benchmark batch size 238 with inference average time 17.3422ms - throughput 13723.8 nps.
Benchmark batch size 239 with inference average time 17.344ms - throughput 13780 nps.
Benchmark batch size 240 with inference average time 17.4376ms - throughput 13763.4 nps.
Benchmark batch size 241 with inference average time 17.6219ms - throughput 13676.1 nps.
Benchmark batch size 242 with inference average time 17.6273ms - throughput 13728.7 nps.
Benchmark batch size 243 with inference average time 17.686ms - throughput 13739.7 nps.
Benchmark batch size 244 with inference average time 17.7377ms - throughput 13756 nps.
Benchmark batch size 245 with inference average time 17.9194ms - throughput 13672.4 nps.
Benchmark batch size 246 with inference average time 18.0326ms - throughput 13642 nps.
Benchmark batch size 247 with inference average time 17.9712ms - throughput 13744.2 nps.
Benchmark batch size 248 with inference average time 17.9681ms - throughput 13802.2 nps.
Benchmark batch size 249 with inference average time 18.1494ms - throughput 13719.5 nps.
Benchmark batch size 250 with inference average time 18.2465ms - throughput 13701.3 nps.
Benchmark batch size 251 with inference average time 18.2297ms - throughput 13768.7 nps.
Benchmark batch size 252 with inference average time 18.4041ms - throughput 13692.6 nps.
Benchmark batch size 253 with inference average time 18.5134ms - throughput 13665.8 nps.
Benchmark batch size 254 with inference average time 18.5746ms - throughput 13674.6 nps.
Benchmark batch size 255 with inference average time 18.6649ms - throughput 13662 nps.
Benchmark batch size 256 with inference average time 18.6473ms - throughput 13728.6 nps.
Benchmark batch size 257 with inference average time 18.9376ms - throughput 13570.9 nps.
Benchmark batch size 258 with inference average time 18.9183ms - throughput 13637.6 nps.
Benchmark batch size 259 with inference average time 18.9652ms - throughput 13656.6 nps.
Benchmark batch size 260 with inference average time 19.0407ms - throughput 13655 nps.
Benchmark batch size 261 with inference average time 18.982ms - throughput 13749.9 nps.
Benchmark batch size 262 with inference average time 19.0468ms - throughput 13755.6 nps.
Benchmark batch size 263 with inference average time 19.1791ms - throughput 13712.8 nps.
Benchmark batch size 264 with inference average time 19.3619ms - throughput 13635 nps.
Benchmark batch size 265 with inference average time 19.3192ms - throughput 13716.9 nps.
Benchmark batch size 266 with inference average time 19.2844ms - throughput 13793.5 nps.
Benchmark batch size 267 with inference average time 19.6178ms - throughput 13610.1 nps.
Benchmark batch size 268 with inference average time 19.532ms - throughput 13721.1 nps.
Benchmark batch size 269 with inference average time 19.5797ms - throughput 13738.8 nps.
Benchmark batch size 270 with inference average time 19.7561ms - throughput 13666.7 nps.
Benchmark batch size 271 with inference average time 19.7883ms - throughput 13695 nps.
Benchmark batch size 272 with inference average time 19.8255ms - throughput 13719.7 nps.
Benchmark batch size 273 with inference average time 19.8439ms - throughput 13757.4 nps.
Benchmark batch size 274 with inference average time 19.8144ms - throughput 13828.3 nps.
Benchmark batch size 275 with inference average time 19.967ms - throughput 13772.7 nps.
Benchmark batch size 276 with inference average time 20.0287ms - throughput 13780.2 nps.
Benchmark batch size 277 with inference average time 20.0776ms - throughput 13796.5 nps.
Benchmark batch size 278 with inference average time 20.1313ms - throughput 13809.3 nps.
Benchmark batch size 279 with inference average time 20.1622ms - throughput 13837.8 nps.
Benchmark batch size 280 with inference average time 20.1774ms - throughput 13876.9 nps.
Benchmark batch size 281 with inference average time 20.2069ms - throughput 13906.2 nps.
Benchmark batch size 282 with inference average time 20.2583ms - throughput 13920.2 nps.
Benchmark batch size 283 with inference average time 20.2744ms - throughput 13958.5 nps.
Benchmark batch size 284 with inference average time 20.2144ms - throughput 14049.4 nps.
Benchmark batch size 285 with inference average time 20.2726ms - throughput 14058.4 nps.
Benchmark batch size 286 with inference average time 20.3704ms - throughput 14040 nps.
Benchmark batch size 287 with inference average time 20.4151ms - throughput 14058.2 nps.
Benchmark batch size 288 with inference average time 20.4094ms - throughput 14111.1 nps.
Benchmark batch size 289 with inference average time 20.6684ms - throughput 13982.7 nps.
Benchmark batch size 290 with inference average time 20.7761ms - throughput 13958.3 nps.
Benchmark batch size 291 with inference average time 20.8251ms - throughput 13973.5 nps.
Benchmark batch size 292 with inference average time 20.848ms - throughput 14006.1 nps.
Benchmark batch size 293 with inference average time 20.8931ms - throughput 14023.7 nps.
Benchmark batch size 294 with inference average time 20.9183ms - throughput 14054.7 nps.
Benchmark batch size 295 with inference average time 20.9482ms - throughput 14082.4 nps.
Benchmark batch size 296 with inference average time 20.9654ms - throughput 14118.5 nps.
Benchmark batch size 297 with inference average time 20.9677ms - throughput 14164.6 nps.
Benchmark batch size 298 with inference average time 21.0147ms - throughput 14180.5 nps.
Benchmark batch size 299 with inference average time 21.047ms - throughput 14206.3 nps.
Benchmark batch size 300 with inference average time 21.1454ms - throughput 14187.5 nps.
Benchmark batch size 301 with inference average time 21.1251ms - throughput 14248.4 nps.
Benchmark batch size 302 with inference average time 21.1894ms - throughput 14252.4 nps.
Benchmark batch size 303 with inference average time 21.1892ms - throughput 14299.7 nps.
Benchmark batch size 304 with inference average time 21.1503ms - throughput 14373.3 nps.
Benchmark batch size 305 with inference average time 21.351ms - throughput 14285 nps.
Benchmark batch size 306 with inference average time 21.4194ms - throughput 14286.1 nps.
Benchmark batch size 307 with inference average time 21.4511ms - throughput 14311.6 nps.
Benchmark batch size 308 with inference average time 21.494ms - throughput 14329.6 nps.
Benchmark batch size 309 with inference average time 21.5384ms - throughput 14346.5 nps.
Benchmark batch size 310 with inference average time 21.5672ms - throughput 14373.7 nps.
Benchmark batch size 311 with inference average time 21.6179ms - throughput 14386.2 nps.
Benchmark batch size 312 with inference average time 21.6132ms - throughput 14435.6 nps.
Benchmark batch size 313 with inference average time 21.6779ms - throughput 14438.7 nps.
Benchmark batch size 314 with inference average time 21.7232ms - throughput 14454.6 nps.
Benchmark batch size 315 with inference average time 21.7999ms - throughput 14449.6 nps.
Benchmark batch size 316 with inference average time 21.7884ms - throughput 14503.2 nps.
Benchmark batch size 317 with inference average time 21.8316ms - throughput 14520.3 nps.
Benchmark batch size 318 with inference average time 21.8678ms - throughput 14541.9 nps.
Benchmark batch size 319 with inference average time 21.9359ms - throughput 14542.4 nps.
Benchmark batch size 320 with inference average time 21.9066ms - throughput 14607.4 nps.
Benchmark batch size 321 with inference average time 22.6971ms - throughput 14142.8 nps.
Benchmark batch size 322 with inference average time 22.7581ms - throughput 14148.8 nps.
Benchmark batch size 323 with inference average time 22.8152ms - throughput 14157.3 nps.
Benchmark batch size 324 with inference average time 22.8826ms - throughput 14159.2 nps.
Benchmark batch size 325 with inference average time 22.9507ms - throughput 14160.8 nps.
Benchmark batch size 326 with inference average time 22.9894ms - throughput 14180.5 nps.
Benchmark batch size 327 with inference average time 23.0046ms - throughput 14214.5 nps.
Benchmark batch size 328 with inference average time 23.0462ms - throughput 14232.3 nps.
Benchmark batch size 329 with inference average time 23.2124ms - throughput 14173.5 nps.
Benchmark batch size 330 with inference average time 23.277ms - throughput 14177.1 nps.
Benchmark batch size 331 with inference average time 23.4534ms - throughput 14113.1 nps.
Benchmark batch size 332 with inference average time 23.5863ms - throughput 14076 nps.
Benchmark batch size 333 with inference average time 23.5567ms - throughput 14136.1 nps.
Benchmark batch size 334 with inference average time 23.7839ms - throughput 14043.1 nps.
Benchmark batch size 335 with inference average time 23.7239ms - throughput 14120.8 nps.
Benchmark batch size 336 with inference average time 23.4919ms - throughput 14302.8 nps.
Benchmark batch size 337 with inference average time 23.648ms - throughput 14250.7 nps.
Benchmark batch size 338 with inference average time 23.7746ms - throughput 14216.9 nps.
Benchmark batch size 339 with inference average time 23.6799ms - throughput 14315.9 nps.
Benchmark batch size 340 with inference average time 23.8896ms - throughput 14232.1 nps.
Benchmark batch size 341 with inference average time 23.9051ms - throughput 14264.8 nps.
Benchmark batch size 342 with inference average time 23.8657ms - throughput 14330.2 nps.
Benchmark batch size 343 with inference average time 23.9098ms - throughput 14345.6 nps.
Benchmark batch size 344 with inference average time 24.0571ms - throughput 14299.3 nps.
Benchmark batch size 345 with inference average time 24.2066ms - throughput 14252.3 nps.
Benchmark batch size 346 with inference average time 24.2594ms - throughput 14262.5 nps.
Benchmark batch size 347 with inference average time 24.1435ms - throughput 14372.4 nps.
Benchmark batch size 348 with inference average time 24.3876ms - throughput 14269.6 nps.
Benchmark batch size 349 with inference average time 24.4372ms - throughput 14281.5 nps.
Benchmark batch size 350 with inference average time 24.7252ms - throughput 14155.6 nps.
Benchmark batch size 351 with inference average time 24.6743ms - throughput 14225.3 nps.
Benchmark batch size 352 with inference average time 24.7142ms - throughput 14242.8 nps.
Benchmark batch size 353 with inference average time 25.1457ms - throughput 14038.2 nps.
Benchmark batch size 354 with inference average time 25.125ms - throughput 14089.6 nps.
Benchmark batch size 355 with inference average time 25.0733ms - throughput 14158.5 nps.
Benchmark batch size 356 with inference average time 25.1213ms - throughput 14171.3 nps.
Benchmark batch size 357 with inference average time 25.0615ms - throughput 14245 nps.
Benchmark batch size 358 with inference average time 25.1855ms - throughput 14214.5 nps.
Benchmark batch size 359 with inference average time 25.2053ms - throughput 14243.1 nps.
Benchmark batch size 360 with inference average time 25.0955ms - throughput 14345.2 nps.
Benchmark batch size 361 with inference average time 25.3079ms - throughput 14264.3 nps.
Benchmark batch size 362 with inference average time 25.36ms - throughput 14274.4 nps.
Benchmark batch size 363 with inference average time 25.3632ms - throughput 14312.1 nps.
Benchmark batch size 364 with inference average time 25.4826ms - throughput 14284.2 nps.
Benchmark batch size 365 with inference average time 25.4364ms - throughput 14349.5 nps.
Benchmark batch size 366 with inference average time 25.4621ms - throughput 14374.3 nps.
Benchmark batch size 367 with inference average time 25.5979ms - throughput 14337.1 nps.
Benchmark batch size 368 with inference average time 25.7336ms - throughput 14300.3 nps.
Benchmark batch size 369 with inference average time 25.6421ms - throughput 14390.4 nps.
Benchmark batch size 370 with inference average time 25.7016ms - throughput 14396 nps.
Benchmark batch size 371 with inference average time 25.7533ms - throughput 14405.9 nps.
Benchmark batch size 372 with inference average time 25.8323ms - throughput 14400.6 nps.
Benchmark batch size 373 with inference average time 25.9031ms - throughput 14399.8 nps.
Benchmark batch size 374 with inference average time 25.9365ms - throughput 14419.9 nps.
Benchmark batch size 375 with inference average time 25.9342ms - throughput 14459.7 nps.
Benchmark batch size 376 with inference average time 26.0483ms - throughput 14434.7 nps.
Benchmark batch size 377 with inference average time 26.0416ms - throughput 14476.8 nps.
Benchmark batch size 378 with inference average time 26.0874ms - throughput 14489.8 nps.
Benchmark batch size 379 with inference average time 26.1402ms - throughput 14498.7 nps.
Benchmark batch size 380 with inference average time 26.2169ms - throughput 14494.5 nps.
Benchmark batch size 381 with inference average time 26.1419ms - throughput 14574.3 nps.
Benchmark batch size 382 with inference average time 26.239ms - throughput 14558.5 nps.
Benchmark batch size 383 with inference average time 26.2718ms - throughput 14578.4 nps.
Benchmark batch size 384 with inference average time 26.1899ms - throughput 14662.1 nps.
Benchmark batch size 385 with inference average time 26.738ms - throughput 14399 nps.
Benchmark batch size 386 with inference average time 26.8628ms - throughput 14369.3 nps.
Benchmark batch size 387 with inference average time 26.8263ms - throughput 14426.2 nps.
Benchmark batch size 388 with inference average time 26.7992ms - throughput 14478.1 nps.
Benchmark batch size 389 with inference average time 26.7353ms - throughput 14550 nps.
Benchmark batch size 390 with inference average time 26.8394ms - throughput 14530.9 nps.
Benchmark batch size 391 with inference average time 26.8012ms - throughput 14588.9 nps.
Benchmark batch size 392 with inference average time 26.9723ms - throughput 14533.4 nps.
Benchmark batch size 393 with inference average time 27.0106ms - throughput 14549.8 nps.
Benchmark batch size 394 with inference average time 26.9788ms - throughput 14604.1 nps.
Benchmark batch size 395 with inference average time 27.0296ms - throughput 14613.6 nps.
Benchmark batch size 396 with inference average time 27.0563ms - throughput 14636.2 nps.
Benchmark batch size 397 with inference average time 27.1454ms - throughput 14624.9 nps.
Benchmark batch size 398 with inference average time 27.1737ms - throughput 14646.5 nps.
Benchmark batch size 399 with inference average time 27.2662ms - throughput 14633.5 nps.
Benchmark batch size 400 with inference average time 27.2598ms - throughput 14673.6 nps.
Benchmark batch size 401 with inference average time 27.4141ms - throughput 14627.5 nps.
Benchmark batch size 402 with inference average time 27.4268ms - throughput 14657.2 nps.
Benchmark batch size 403 with inference average time 27.3879ms - throughput 14714.5 nps.
Benchmark batch size 404 with inference average time 27.4347ms - throughput 14725.9 nps.
Benchmark batch size 405 with inference average time 27.475ms - throughput 14740.7 nps.
Benchmark batch size 406 with inference average time 27.5731ms - throughput 14724.5 nps.
Benchmark batch size 407 with inference average time 27.5896ms - throughput 14751.9 nps.
Benchmark batch size 408 with inference average time 27.6483ms - throughput 14756.8 nps.
Benchmark batch size 409 with inference average time 27.6659ms - throughput 14783.5 nps.
Benchmark batch size 410 with inference average time 27.6886ms - throughput 14807.5 nps.
Benchmark batch size 411 with inference average time 27.7781ms - throughput 14795.8 nps.
Benchmark batch size 412 with inference average time 27.8426ms - throughput 14797.5 nps.
Benchmark batch size 413 with inference average time 28.0314ms - throughput 14733.5 nps.
Benchmark batch size 414 with inference average time 27.9914ms - throughput 14790.2 nps.
Benchmark batch size 415 with inference average time 27.9955ms - throughput 14823.8 nps.
Benchmark batch size 416 with inference average time 28.0648ms - throughput 14822.8 nps.
Benchmark batch size 417 with inference average time 28.8202ms - throughput 14469 nps.
Benchmark batch size 418 with inference average time 28.8387ms - throughput 14494.4 nps.
Benchmark batch size 419 with inference average time 28.9429ms - throughput 14476.8 nps.
Benchmark batch size 420 with inference average time 29.0061ms - throughput 14479.7 nps.
Benchmark batch size 421 with inference average time 29.0873ms - throughput 14473.7 nps.
Benchmark batch size 422 with inference average time 29.0202ms - throughput 14541.6 nps.
Benchmark batch size 423 with inference average time 28.9941ms - throughput 14589.2 nps.
Benchmark batch size 424 with inference average time 29.0245ms - throughput 14608.3 nps.
Benchmark batch size 425 with inference average time 29.2165ms - throughput 14546.6 nps.
Benchmark batch size 426 with inference average time 29.2824ms - throughput 14548 nps.
Benchmark batch size 427 with inference average time 29.3341ms - throughput 14556.4 nps.
Benchmark batch size 428 with inference average time 29.315ms - throughput 14600 nps.
Benchmark batch size 429 with inference average time 29.4911ms - throughput 14546.8 nps.
Benchmark batch size 430 with inference average time 29.4866ms - throughput 14582.9 nps.
Benchmark batch size 431 with inference average time 29.4948ms - throughput 14612.7 nps.
Benchmark batch size 432 with inference average time 29.5358ms - throughput 14626.3 nps.
Benchmark batch size 433 with inference average time 29.7022ms - throughput 14578 nps.
Benchmark batch size 434 with inference average time 29.6807ms - throughput 14622.3 nps.
Benchmark batch size 435 with inference average time 29.9009ms - throughput 14548.1 nps.
Benchmark batch size 436 with inference average time 29.8834ms - throughput 14590 nps.
Benchmark batch size 437 with inference average time 29.9689ms - throughput 14581.8 nps.
Benchmark batch size 438 with inference average time 29.9878ms - throughput 14606 nps.
Benchmark batch size 439 with inference average time 30.0528ms - throughput 14607.6 nps.
Benchmark batch size 440 with inference average time 30.1006ms - throughput 14617.6 nps.
Benchmark batch size 441 with inference average time 30.1815ms - throughput 14611.6 nps.
Benchmark batch size 442 with inference average time 30.1762ms - throughput 14647.3 nps.
Benchmark batch size 443 with inference average time 30.2634ms - throughput 14638.1 nps.
Benchmark batch size 444 with inference average time 30.2742ms - throughput 14666 nps.
Benchmark batch size 445 with inference average time 30.2654ms - throughput 14703.3 nps.
Benchmark batch size 446 with inference average time 30.2476ms - throughput 14745 nps.
Benchmark batch size 447 with inference average time 30.3749ms - throughput 14716.1 nps.
Benchmark batch size 448 with inference average time 30.3072ms - throughput 14782 nps.
Benchmark batch size 449 with inference average time 30.6405ms - throughput 14653.8 nps.
Benchmark batch size 450 with inference average time 30.7288ms - throughput 14644.3 nps.
Benchmark batch size 451 with inference average time 30.8875ms - throughput 14601.4 nps.
Benchmark batch size 452 with inference average time 30.9787ms - throughput 14590.7 nps.
Benchmark batch size 453 with inference average time 30.9173ms - throughput 14652 nps.
Benchmark batch size 454 with inference average time 30.9915ms - throughput 14649.2 nps.
Benchmark batch size 455 with inference average time 30.9193ms - throughput 14715.8 nps.
Benchmark batch size 456 with inference average time 30.8234ms - throughput 14793.9 nps.
Benchmark batch size 457 with inference average time 30.9459ms - throughput 14767.7 nps.
Benchmark batch size 458 with inference average time 31.213ms - throughput 14673.4 nps.
Benchmark batch size 459 with inference average time 31.4315ms - throughput 14603.2 nps.
Benchmark batch size 460 with inference average time 31.3953ms - throughput 14651.9 nps.
Benchmark batch size 461 with inference average time 31.3059ms - throughput 14725.7 nps.
Benchmark batch size 462 with inference average time 31.3467ms - throughput 14738.4 nps.
Benchmark batch size 463 with inference average time 31.3579ms - throughput 14765 nps.
Benchmark batch size 464 with inference average time 31.4477ms - throughput 14754.6 nps.
Benchmark batch size 465 with inference average time 31.5798ms - throughput 14724.6 nps.
Benchmark batch size 466 with inference average time 31.5537ms - throughput 14768.5 nps.
Benchmark batch size 467 with inference average time 31.4416ms - throughput 14853 nps.
Benchmark batch size 468 with inference average time 31.5228ms - throughput 14846.4 nps.
Benchmark batch size 469 with inference average time 31.6525ms - throughput 14817.1 nps.
Benchmark batch size 470 with inference average time 31.5858ms - throughput 14880.1 nps.
Benchmark batch size 471 with inference average time 31.713ms - throughput 14852 nps.
Benchmark batch size 472 with inference average time 31.8485ms - throughput 14820.2 nps.
Benchmark batch size 473 with inference average time 31.8816ms - throughput 14836.2 nps.
Benchmark batch size 474 with inference average time 31.8279ms - throughput 14892.6 nps.
Benchmark batch size 475 with inference average time 31.9783ms - throughput 14853.8 nps.
Benchmark batch size 476 with inference average time 32.0118ms - throughput 14869.5 nps.
Benchmark batch size 477 with inference average time 31.9255ms - throughput 14941 nps.
Benchmark batch size 478 with inference average time 32.0191ms - throughput 14928.6 nps.
Benchmark batch size 479 with inference average time 32.0777ms - throughput 14932.5 nps.
Benchmark batch size 480 with inference average time 32.0717ms - throughput 14966.5 nps.
Benchmark batch size 481 with inference average time 32.5355ms - throughput 14783.8 nps.
Benchmark batch size 482 with inference average time 32.4658ms - throughput 14846.4 nps.
Benchmark batch size 483 with inference average time 32.5827ms - throughput 14823.8 nps.
Benchmark batch size 484 with inference average time 32.5674ms - throughput 14861.5 nps.
Benchmark batch size 485 with inference average time 32.628ms - throughput 14864.6 nps.
Benchmark batch size 486 with inference average time 32.7282ms - throughput 14849.6 nps.
Benchmark batch size 487 with inference average time 32.8002ms - throughput 14847.5 nps.
Benchmark batch size 488 with inference average time 32.8211ms - throughput 14868.5 nps.
Benchmark batch size 489 with inference average time 32.9106ms - throughput 14858.4 nps.
Benchmark batch size 490 with inference average time 32.913ms - throughput 14887.7 nps.
Benchmark batch size 491 with inference average time 33.0089ms - throughput 14874.8 nps.
Benchmark batch size 492 with inference average time 32.9924ms - throughput 14912.5 nps.
Benchmark batch size 493 with inference average time 33.1119ms - throughput 14888.9 nps.
Benchmark batch size 494 with inference average time 33.1208ms - throughput 14915.1 nps.
Benchmark batch size 495 with inference average time 33.1176ms - throughput 14946.7 nps.
Benchmark batch size 496 with inference average time 33.5007ms - throughput 14805.7 nps.
Benchmark batch size 497 with inference average time 33.6357ms - throughput 14776 nps.
Benchmark batch size 498 with inference average time 33.781ms - throughput 14742 nps.
Benchmark batch size 499 with inference average time 33.9107ms - throughput 14715.1 nps.
Benchmark batch size 500 with inference average time 33.8657ms - throughput 14764.2 nps.
Benchmark batch size 501 with inference average time 33.7001ms - throughput 14866.4 nps.
Benchmark batch size 502 with inference average time 33.7207ms - throughput 14887 nps.
Benchmark batch size 503 with inference average time 33.7882ms - throughput 14886.9 nps.
Benchmark batch size 504 with inference average time 33.7448ms - throughput 14935.6 nps.
Benchmark batch size 505 with inference average time 33.7898ms - throughput 14945.3 nps.
Benchmark batch size 506 with inference average time 33.8644ms - throughput 14942 nps.
Benchmark batch size 507 with inference average time 34.0761ms - throughput 14878.5 nps.
Benchmark batch size 508 with inference average time 34.0663ms - throughput 14912.1 nps.
Benchmark batch size 509 with inference average time 34.1015ms - throughput 14926 nps.
Benchmark batch size 510 with inference average time 34.2432ms - throughput 14893.5 nps.
Benchmark batch size 511 with inference average time 34.2764ms - throughput 14908.2 nps.
Benchmark batch size 512 with inference average time 34.0292ms - throughput 15045.9 nps.
